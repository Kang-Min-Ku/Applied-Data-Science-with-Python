{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "%precision 2\n",
    "\n",
    "with open('datasets/mpg.csv') as csvfile:\n",
    "    mpg = list(csv.DictReader(csvfile))\n",
    "#mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812.40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(float(d['displ']) for d in mpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pythonstudy.xyz/python/article/23-Iterator%EC%99%80-Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812.40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = iter(float(d['displ']) for d in mpg)\n",
    "sum(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "time = time.time()\n",
    "dtnow = dt.datetime.fromtimestamp(time)\n",
    "dtnow.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 11, 9, 10, 42, 11, 76660)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = dt.timedelta(days=300)\n",
    "dtnow - delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Python doesn't have private or protected, all instances and methods are public\n",
    "2. map built-in func is one example of a functional programming feature\n",
    "\n",
    "# Map Function\n",
    "1. Functional programming is a programming paradigm in which you explicitly declare all parameters which could change through execution of a given function. Thus functional programming is referred to as being side-effect free, because there is a software contract that describes what can actually change by calling a function. Now, Python isn't a functional programming language in the pure sense. Since you can have many side effects of functions, and certainly you don't have to pass in the parameters of everything that you're interested in changing. But functional programming causes one to think more heavily while chaining operations together. And this really is a sort of underlying theme in much of data science and date cleaning in particular.\n",
    " \n",
    "2. Check Python documentation about map\n",
    "3. Python의 map object는 lazy evaluation -> user가 result나 contents 보기 전까지는 계산 안함 -> efficient memory management\n",
    "4. This passing around of functions and data structures which they should be applied to, is a hallmark of functional programming. It's very common in data analysis and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Brooks', 'Dr. Collins-Thompson', 'Dr. Vydiswaran', 'Dr. Romero']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quiz about map() function\n",
    "people = ['Dr. Christopher Brooks', 'Dr. Kevyn Collins-Thompson', 'Dr. VG Vinod Vydiswaran', 'Dr. Daniel Romero']\n",
    "\n",
    "def split_title_and_name(person):\n",
    "    lst = person.split(' ')\n",
    "    return lst[0] + ' ' + lst[-1]\n",
    "\n",
    "list(map(split_title_and_name, people))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lambda\n",
    "0. anonymous func\n",
    "1. Default value나 Complex Logic은 사용 불가능\n",
    "2. Useful for simple little data cleaning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(a,b):\n",
    "    return a+b\n",
    "\n",
    "func = lambda a, b, c : add(a,b)\n",
    "func(5,55,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Comprehension\n",
    "[(Value you want) (For loop) (Condition)]\n",
    "\n",
    "1. It offer readability and performance benefit(?)\n",
    "<Q> 왜 performance benefit이 있지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7f0f70719a98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[number for number in range(1000) if number > 300 and number%2==1]\n",
    "(number for number in range(1000) if number > 300 and number%2==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_tables():\n",
    "    lst = []\n",
    "    for i in range(10):\n",
    "        for j in range (10):\n",
    "            lst.append(i*j)\n",
    "    return lst\n",
    "\n",
    "#times_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "quiz = [num1*num2 for num1,num2 in list(itertools.product(range(10),range(10)))]\n",
    "times_tables() == quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-3a0212db9552>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-3a0212db9552>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print(txt.findall(?<=https:\\/\\/)([A-Za-z0-9.]*))\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "txt = 'I refer to https://google.com and i never refer http://www.baidu.com'\n",
    "print(txt.findall(?<=https:\\/\\/)([A-Za-z0-9.]*))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
       "       0.71428571, 0.85714286, 1.        , 1.14285714, 1.28571429,\n",
       "       1.42857143, 1.57142857, 1.71428571, 1.85714286, 2.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3,4)\n",
    "np.arange(10,51,3) #Create array with difference k from start to end\n",
    "np.linspace(0,2,15) #Create array with k elements from start to end that has same difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10,50,10)\n",
    "b = np.arange(1,5,1)\n",
    "a-b\n",
    "a+b\n",
    "a*b\n",
    "a/b\n",
    "a**b\n",
    "a@b #Product 내적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If I write code with Array c(not specific element like c[2][3]), code is applied to all variables\n",
    "#This is elementwise operation\n",
    "c = np.random.randint(0,30,(5,6))\n",
    "d = c*9/5+32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False,  True, False, False, False, False],\n",
       "       [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I can also use Conditional operator\n",
    "d > 40\n",
    "d%2==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When manipulating arrays of different types, the type of the result will correspond to\n",
    "#the more general of the two types -> upcasting\n",
    "e = np.linspace(0,2,5)\n",
    "f = np.random.randint(0,5,5)\n",
    "(e+f).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = e+f\n",
    "g.min()\n",
    "g.sum()\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5,6))\n",
    "np.ones((6,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15]]), 25)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = np.arange(1,16,1).reshape(3,5)\n",
    "lst = [3,4,5,6,7]\n",
    "h, sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 40, 65]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map function is appled for each row\n",
    "list(map(lambda x:x.sum(),h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we often think about two dimensional arrays being made up of rows and columns, but you can also think of these arrays as just a **giant ordered list of numbers**, and the *shape* of the array, the number of rows and columns, is just an abstraction that we have for a particular purpose. \n",
    "Actually, **this is exactly how basic images are stored in computer environments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# And let's just look at the image I'm talking about\n",
    "im = Image.open('chris.tiff')\n",
    "im2 = Image.open('god.jpg')\n",
    "#display(im),display(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2c988df043f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0marr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0marr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr2\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0x11001011\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "arr1 = np.array(im)\n",
    "arr2 = np.array(im2)\n",
    "arr3 = arr2 & 0x11001011\n",
    "mask1 = np.full(arr1.shape,255)\n",
    "mask2 = np.full(arr2.shape,255)\n",
    "\n",
    "modified1 = mask1 - arr1\n",
    "modified2 = mask2 - arr2\n",
    "\n",
    "#modified1, modified2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modified1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bc57d184033e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodified1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodified2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodified1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodified1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodified2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0marr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modified1' is not defined"
     ]
    }
   ],
   "source": [
    "modified1.dtype, modified2.dtype\n",
    "modified1= modified1.astype(np.uint8)\n",
    "modified2 = modified2.astype(np.uint8)\n",
    "arr3 = arr3.astype(np.uint8)\n",
    "\n",
    "modified1.dtype, modified2.dtype\n",
    "#modified1,modified2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(Image.fromarray(arr3))\n",
    "#display(Image.fromarray(modified2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((675, 540, 3), (250, 1458, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped1 = np.reshape(arr1,(100,400))\n",
    "reshaped2 = np.reshape(arr2,(250,1458,3))\n",
    "arr2.shape, reshaped2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image.fromarray(reshaped1))\n",
    "#display(Image.fromarray(reshaped2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Can't say I find that particularly flattering. By reshaping the array to be only 100 rows high but 400\n",
    " columns we've essentially doubled the image by taking every other line and stacking them out in width. This\n",
    " makes the image look more stretched out too.\n",
    "\n",
    " This isn't an image manipulation course, but the point was to show you that these numpy arrays are really\n",
    " **just abstractions on top of data, and that data has an underlying format (in this case, uint8).** But further,\n",
    " we can build abstractions on top of that, such as computer code which renders a byte as either black or \n",
    " white, which has meaning to people. In some ways, this whole degree is about data and the abstractions that\n",
    " we can build on top of that data, from individual byte representations through to complex neural networks of\n",
    " functions or interactive visualizations. **Your role as a data scientist is to understand what the data means\n",
    " (it's context an collection), and transform it into a different representation to be used for sensemaking.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[35, 11, 35, 14, 13, 31],\n",
       "        [17, 25, 18, 27, 39, 34],\n",
       "        [25, 31, 11, 26, 37, 31],\n",
       "        [17, 35, 30, 25, 14, 16],\n",
       "        [27, 35, 23, 12, 32, 27]]), array([[17, 25, 18, 27, 39, 34],\n",
       "        [25, 31, 11, 26, 37, 31]]), array([26, 16]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In i[n:k], i[k] is not contained in result\n",
    "i = np.random.randint(10,40,(5,6))\n",
    "i,i[1:3],i[[2,3],[3,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We can use **array of boolean like a mask over the original array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 35, 31, 25, 27, 39, 34, 25, 31, 26, 37, 31, 35, 30, 25, 27, 35,\n",
       "       23, 32, 27])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[i > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 35, 30, 25, 14, 16],\n",
       "       [27, 35, 23, 12, 32, 27]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portion =i[3:5][:5]\n",
    "portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to realize that a slice of an array is a view into the same data. This is called **passing by reference**. So **modifying** the sub array will consequently modify the original array\n",
    "\n",
    "However, array operation of subarray is not applied to original array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  17,   35,   30,   25, 1111,   16],\n",
       "        [  27,   35,   23,   12,   32,   27]]),\n",
       " array([[  35,   11,   35,   14,   13,   31],\n",
       "        [  17,   25,   18,   27,   39,   34],\n",
       "        [  25,   31,   11,   26,   37,   31],\n",
       "        [  17,   35,   30,   25, 1111,   16],\n",
       "        [  27,   35,   23,   12,   32,   27]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<Q> Matrix의 원소들 한 번에 바꾸는 법은 없나\n",
    "#<A> i[row, col] = val\n",
    "i[3][4]=1111\n",
    "#i[4:][:4] = 555 -> 보면 row들은 한 번에 적용이 되는데 column은 적용이 안됨\n",
    "#i[4:,:2] = 666\n",
    "portion,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  27,   45,   40,   35, 1121,   26],\n",
       "        [  37,   45,   33,   22,   42,   37]]),\n",
       " array([[  35,   11,   35,   14,   13,   31],\n",
       "        [  17,   25,   18,   27,   39,   34],\n",
       "        [  25,   31,   11,   26,   37,   31],\n",
       "        [  17,   35,   30,   25, 1111,   16],\n",
       "        [  27,   35,   23,   12,   32,   27]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portion = portion + 10\n",
    "portion,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35, 11, 35, 14, 13, 31],\n",
       "       [17, 25, 18, 27, 39, 34],\n",
       "       [25, 31, 11, 26, 37, 31]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines = np.genfromtxt('datasets/winequality-red.csv',delimiter=\";\",skip_header=1)\n",
    "wines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.075, 0.46 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:5,0].shape,wines[:5,0:1].shape\n",
    "wines[[4,5,6],[2,4,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-af86b6ecfe73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m graduate_admission = np.genfromtxt('datasets/Admission_Predict.csv', dtype=None, delimiter=',', skip_header=1,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                    names=('Serial No','GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n\u001b[1;32m      3\u001b[0m                                           'LOR','CGPA','Research', 'Chance of Admit'))\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#graduate_admission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "graduate_admission = np.genfromtxt('datasets/Admission_Predict.csv', dtype=None, delimiter=',', skip_header=1,\n",
    "                                   names=('Serial No','GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
    "                                          'LOR','CGPA','Research', 'Chance of Admit'))\n",
    "#graduate_admission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admission_Predict.csv가 tuple로 읽히는 이유\n",
    "\n",
    "[Link Stack Overflow](https://stackoverflow.com/questions/9534408/numpy-genfromtxt-produces-array-of-what-looks-like-tuples-not-a-2d-array-why)\n",
    "\n",
    "What is returned is called a structured ndarray, see e.g. here: http://docs.scipy.org/doc/numpy/user/basics.rec.html. This is because your data is not homogeneous, i.e. not all elements have the same type: the data contains both strings (the first two columns) and floats. Numpy arrays have to be homogeneous (see here for an explanation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e5b30bfe9380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraduate_admission2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/Admission_Predict.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#graduate_admission2 = np.genfromtxt('datasets/Admission_Predict.csv', dtype=np.float64, delimiter=',', skip_header=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#graduate_admission2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "graduate_admission2 = np.genfromtxt('datasets/Admission_Predict.csv', dtype=None, delimiter=',', skip_header=1)\n",
    "#graduate_admission2 = np.genfromtxt('datasets/Admission_Predict.csv', dtype=np.float64, delimiter=',', skip_header=1)\n",
    "#graduate_admission2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.65, 9.34, 9.  , 9.5 , 9.7 , 9.8 , 9.6 , 9.4 , 9.6 , 9.8 , 9.2 ,\n",
       "       9.1 , 9.4 , 9.1 , 9.3 , 9.7 , 8.85, 9.64, 9.76, 9.45, 9.04, 9.5 ,\n",
       "       9.22, 9.36, 9.45, 8.96, 9.24, 9.18, 9.46, 9.38, 9.56, 9.48, 9.32,\n",
       "       9.1 , 9.35, 9.76, 9.28, 8.77, 9.15, 9.36, 9.44, 9.92, 8.64, 9.11,\n",
       "       9.8 , 9.43, 9.28, 9.06, 9.01, 9.07, 9.13, 9.23, 8.97, 8.87, 9.16,\n",
       "       9.04, 9.11, 8.68, 9.44, 9.36, 9.08, 9.16, 8.98, 8.94, 9.53, 9.91,\n",
       "       9.87, 9.14, 9.66, 9.78, 9.42, 9.36, 9.26, 9.13, 8.97, 9.01, 9.31,\n",
       "       9.23, 9.17, 9.19, 9.02, 9.68, 9.12, 9.34, 9.13, 9.14, 9.45, 8.79,\n",
       "       9.66, 9.26, 9.19, 9.08, 9.02, 9.11, 9.24, 9.18, 9.14, 9.11, 9.47,\n",
       "       8.74, 8.66, 8.44, 8.64, 9.54, 9.23, 9.17, 9.22, 9.62, 9.15, 9.74,\n",
       "       9.82, 9.12, 9.23, 9.04, 9.11, 9.45, 9.66])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission[graduate_admission['Chance_of_Admit']>0.8]['CGPA']\n",
    "#graduate_admission2[graduate_admission['Chance_of_Admit']>0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression(Regex)\n",
    "\n",
    "[Python regex documentation](https://docs.python.org/3/library/re.html)\n",
    "\n",
    "There's really three main reasons you would want to do this - to check whether a pattern exists within some source data, to get all instances of a complex pattern from some source data, or to clean your source data using a pattern generally through string splitting. Regexes are not trivial, but they are a foundational technique for data cleaning in data science applications, and a solid understanding of regexs will help you quickly and efficiently manipulate text data for further data science application.\n",
    "\n",
    "Now, you could teach a whole course on regular expressions alone, especially if you wanted to demystify how the regex parsing engine works and efficient mechanisms for parsing text. In this lecture I want to give you basic understanding of how regex works - enough knowledge that, with a little directed sleuthing, you'll be able to make sense of the regex patterns you see others use, and you can build up your practical knowledge of how to use regexes to improve your data cleaning. By the end of this lecture, you will understand the basics of regular expressions, how to define patterns for matching, how to apply these patterns to strings, and how to use the results of those patterns in data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Junyuk First\n"
     ]
    }
   ],
   "source": [
    "text = \"I want to go vacance\"\n",
    "if re.search('vacance',text):\n",
    "    print('Junyuk First')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to checking for conditionals, we can segment a string. The work that regex does here is called **tokenizing**, where the string is separated into substrings based on patterns. Tokenizing is a core activity in natural language processing, which we won't talk much about here but that you will study in the future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amy', 'Amy']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Amy Emy Army Wowmy Shaomi Amy Limy\"\n",
    "re.split(\"Amy\",text)\n",
    "re.findall(\"Amy\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='AAmy'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ^ : If start with this string\n",
    "text = \"AAmy!!Go\"\n",
    "re.search(\"^Amy\",text)\n",
    "re.search(\"^AAmy\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'BBB', 'BB', 'BBB']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [] : set operator. In set operator other special characters like ^ loses meaning\n",
    "#      ^ is used for represent \"not\" in set operator\n",
    "# | : or\n",
    "\n",
    "grade = \"AABCDDABBBABCDBBGASDFASDFABBBSDRF@FGASDSEGDWADCAGWREAWGERQWWWQQQGEW\"\n",
    "len(re.findall(\"B\",grade))\n",
    "re.findall(\"[AB]\",grade)\n",
    "re.findall(\"D[A-C]\",grade)\n",
    "re.findall(\"DA|DB|DC\",grade)\n",
    "re.findall(\"[^A-C]\",grade)\n",
    "#D[A-C] = DA|DB|DC\n",
    "#<Q> 어떻게 하면 모든 알파벳에 대해 back to back을 구할 수 있을까? \n",
    "re.findall(\"[B-Z]{2,5}\",grade) #B-Z 사이의 알파벳이 반복되기만 하면 됨\n",
    "re.findall(\"A{2,5}|B{2,5}\",grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/ferpa.txt','r') as file:\n",
    "    wiki = file.read()\n",
    "#wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overview[edit]',\n",
       " 'Access to public records[edit]',\n",
       " 'Student medical records[edit]']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\s : white space \n",
    "# \\w : any digit and letter\n",
    "# \\d : any digit\n",
    "re.findall('[\\sa-zA-Z]{1,1000}\\[edit\\]',wiki)\n",
    "re.findall('[\\s\\w]{1,1000}\\[edit\\]',wiki)\n",
    "re.findall('[ \\w]{1,1000}\\[edit\\]',wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to public records[edit]\n",
      "Student medical records[edit]\n"
     ]
    }
   ],
   "source": [
    "#about group\n",
    "#format : (regex1)(regex2)(regex3)\n",
    "#m.group(n) n번째 그룹에 매칭된 문자열 반환\n",
    "#m.group() return total result\n",
    "re.findall('([\\w]*)(\\[edit\\])',wiki)\n",
    "for item in re.finditer('([\\w ]*)([^view])(\\[edit\\])',wiki):\n",
    "    print(item.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview[edit]\n",
      "Access to public records[edit]\n",
      "Student medical records[edit]\n"
     ]
    }
   ],
   "source": [
    "#Can do labeling or naming groups by get result as dictionary\n",
    "#finditer -> iterator로 return\n",
    "for item in re.finditer('(?P<name>[\\w ]*)(?P<edit_link>\\[edit\\])',wiki):\n",
    "    print(item.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-19528a1ffa6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#look-ahead : Use regex to match but don't want to captrue them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#look-behind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?P<title>[\\w ]+)(?P<etc>?=[ed])'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'etc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfinditer\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 426\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    814\u001b[0m             sub_verbose = ((verbose or (add_flags & SRE_FLAG_VERBOSE)) and\n\u001b[1;32m    815\u001b[0m                            not (del_flags & SRE_FLAG_VERBOSE))\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_verbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 raise source.error(\"missing ), unterminated subpattern\",\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 426\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mAT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 raise source.error(\"nothing to repeat\",\n\u001b[0;32m--> 651\u001b[0;31m                                    source.tell() - here + len(this))\n\u001b[0m\u001b[1;32m    652\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                 raise source.error(\"multiple repeat\",\n",
      "\u001b[0;31merror\u001b[0m: nothing to repeat at position 25"
     ]
    }
   ],
   "source": [
    "#look-ahead : Use regex to match but don't want to captrue them use \"?=\"\n",
    "#look-behind\n",
    "for item in re.finditer('(?P<title>[\\w ]+)(?=[ed])',wiki):\n",
    "    print(item.group('etc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/buddhist.txt\",\"r\") as file:\n",
    "    wiki = file.read()\n",
    "#wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '\\n\\nDhammakaya Open University ', 'city': 'Azusa', 'state': 'California'}\n",
      "{'title': '\\nDharmakirti College ', 'city': 'Tucson', 'state': 'Arizona'}\n",
      "{'title': '\\nDharma Realm Buddhist University ', 'city': 'Ukiah', 'state': 'California'}\n",
      "{'title': '\\nEwam Buddhist Institute ', 'city': 'Arlee', 'state': 'Montana'}\n",
      "{'title': '\\nInstitute of Buddhist Studies ', 'city': 'Berkeley', 'state': 'California'}\n",
      "{'title': '\\nMaitripa College ', 'city': 'Portland', 'state': 'Oregon'}\n",
      "{'title': ' California\\nUniversity of the West ', 'city': 'Rosemead', 'state': 'California'}\n",
      "{'title': '\\nWon Institute of Graduate Studies ', 'city': 'Glenside', 'state': 'Pennsylvania'}\n"
     ]
    }
   ],
   "source": [
    "#verbose mode : write multi line regex\n",
    "pattern = \"\"\"\n",
    "(?P<title>\\n[\\w\\s]*) \n",
    "(–\\ located\\ in\\ )\n",
    "(?P<city>\\w*)\n",
    "(,\\ )\n",
    "(?P<state>\\w*)\n",
    "\"\"\"\n",
    "for item in re.finditer(pattern,wiki,re.VERBOSE):\n",
    "    print(item.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/nytimeshealth.txt\",\"r\") as file:\n",
    "    ny = file.read()\n",
    "#ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"#[\\w]*(=?\\s)\"\n",
    "#for item in re.finditer(pattern,ny):\n",
    "#    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p', 'p', 'l']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#특정 regex 반복하는 방법? url 문제\n",
    "#?:\n",
    "re.findall(\"[\\w_^.]{2,}\\.[\\w_]{2,}\",\"a..com.ddd\")\n",
    "re.findall(\"[^aeiou]\",\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Capture email address with letters, numbers, underscore and dots. A valid email address defined in this problem must meet the following requirements:\n",
    "Has an \"@\" symbol;\n",
    "Before the \"@\" symbol, there can be one or more strings made of letters, numbers and underscores, separated by a single dot.\n",
    "After the \"@\" symbol, there can two or more strings made of letters, numbers and underscores, separated by a single dot.\n",
    "No other characters besides letters, numbers, underscores, dots, and the \"@\" symbol should appear in the email address.\n",
    "\n",
    "For example, your regular expression should match email addresses like: abc@umich.edu, 8ab.c_def9@example.regex.com;\n",
    "But your regex should not match: abc@ def., ab..abc@def.com, abc@def\n",
    "Your regular expression:\n",
    "Drag or click to select from the symbols below to form your regex\n",
    "@+*\\w\\.(\\w+\\.)(\\w*\\.)\n",
    "Regex:\n",
    "Feel free to experiment with your own test cases.\n",
    "Match:\n",
    "abc@umich.edu\n",
    "\n",
    "8ab.c_def9@example.regex.com\n",
    "\n",
    "Reset\n",
    "Do not match:\n",
    "abc@ def.\n",
    "\n",
    "ab..abc@def.com\n",
    "\n",
    "abc@def\n",
    "\n",
    "Reset\n",
    "\n",
    "Drag or click to select from the symbols below to form your regex\n",
    "@+*\\w\\.(\\w+\\.)(\\w*\\.)\n",
    "Regex:\n",
    "(\\w+\\.)*\\w+@(\\w+\\.)+\\w+ #단어를 반복시키고 싶으면 grouping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
